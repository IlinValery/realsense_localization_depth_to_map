{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial preparation by Valery Ilin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified by: Elvira Zainulina\n",
    "\n",
    "Post modif: Valery Ilin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting frames for next dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_of_frames = 20\n",
    "frames_between_frames_D435 = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_of_frames * frames_between_frames_D435 / 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iitial configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data filenames\n",
    "d435_filename = '../data/D435.bag'\n",
    "t265_filename = '../data/T265.bag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config fo D435\n",
    "cfg_d435 = rs.config()\n",
    "cfg_d435.enable_device_from_file(d435_filename)\n",
    "cfg_d435.enable_stream(rs.stream.depth, 848, 480, rs.format.z16, 30)\n",
    "pipe_d435 = rs.pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config fo T265\n",
    "cfg_t265 = rs.config()\n",
    "cfg_t265.enable_device_from_file(t265_filename)\n",
    "cfg_t265.enable_stream(rs.stream.pose)\n",
    "pipe_t265 = rs.pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all data from 265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_timestamp 1585059273040.0645\n",
      "reached the first frame - reading bag file completed\n"
     ]
    }
   ],
   "source": [
    "cfg = rs.config()\n",
    "cfg.enable_device_from_file(t265_filename)\n",
    "cfg.enable_stream(rs.stream.pose)\n",
    "pipe = rs.pipeline()\n",
    "profile = pipe.start(cfg)\n",
    "\n",
    "t265_data_list = []\n",
    "t265_time_list = []\n",
    "first_timestamp = None\n",
    "while(True):\n",
    "\n",
    "    frames = pipe.wait_for_frames()\n",
    "    pose = frames.get_pose_frame()\n",
    "    \n",
    "    if pose:\n",
    "        if pose.get_timestamp() == first_timestamp:\n",
    "            print('reached the first frame - reading bag file completed')\n",
    "            break\n",
    "        if first_timestamp is None:\n",
    "            first_timestamp = pose.get_timestamp()\n",
    "            print('initial_timestamp',first_timestamp)\n",
    "#         print('current-first',pose.get_timestamp()-first_timestamp)\n",
    "        t265_data_list.append(pose.get_pose_data())\n",
    "        t265_time_list.append(pose.get_timestamp())\n",
    "    \n",
    "pipe.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6146"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t265_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translation_pose_from_data(pose):\n",
    "    # https://github.com/IntelRealSense/librealsense/issues/5178\n",
    "    try:\n",
    "        trans = pose.translation\n",
    "#         return np.array([-trans.z, trans.x, -trans.y]) # world(x,y,z) = real(-z,x,-y)\n",
    "        return np.array([trans.x, trans.y, trans.z]) # world(x,y,z) = real(-z,x,-y)\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "t265_frames_all = t265_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00132552,  0.00054592,  0.00075021])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_translation_pose_from_data(t265_frames_all[60])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "d435_frames = []\n",
    "pipe_d435.start(cfg_d435)\n",
    "while len(d435_frames) != count_of_frames:\n",
    "    for i in range(frames_between_frames_D435):\n",
    "        depth_frame = pipe_d435.wait_for_frames().get_depth_frame()\n",
    "    d435_frames.append(depth_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "wait_for_frames cannot be called before start()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f95f4f214ead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdepth_frame_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdepth_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth_frame_time\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpose_frame_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpose_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe_t265\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pose_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mpose_frame_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpose_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth_frame_time\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpose_frame_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: wait_for_frames cannot be called before start()"
     ]
    }
   ],
   "source": [
    "# pipe_t265.start(cfg_t265)\n",
    "\n",
    "pose_frame = None\n",
    "pose_frame_time = -1\n",
    "thresh = 5\n",
    "t265_frames = []\n",
    "t265_frames_temp = []\n",
    "n = 0\n",
    "\n",
    "for i, depth_frame in enumerate(d435_frames):\n",
    "    depth_frame_time = depth_frame.get_timestamp()\n",
    "    while abs(depth_frame_time-pose_frame_time) > thresh:\n",
    "        pose_frame = pipe_t265.wait_for_frames().get_pose_frame()\n",
    "        pose_frame_time = pose_frame.get_timestamp()\n",
    "    while abs(depth_frame_time-pose_frame_time) <= thresh:\n",
    "        pose_frame = pipe_t265.wait_for_frames().get_pose_frame()\n",
    "        t265_frames_temp.append(pose_frame)\n",
    "        pose_frame_time = pose_frame.get_timestamp()\n",
    "\n",
    "    min_int_index = 0\n",
    "    min_interval = thresh * 2\n",
    "    for ind_pose, temp_pose in enumerate(t265_frames_temp):\n",
    "        if abs(depth_frame_time-temp_pose.get_timestamp())<min_interval:\n",
    "            min_interval = abs(depth_frame_time-temp_pose.get_timestamp())\n",
    "            min_int_index = ind_pose\n",
    "    t265_frames.append(t265_frames_temp[min_int_index])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6215d7b0>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6215d670>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6215df30>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6215d6f0>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6215d7b0>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6215def0>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6216c770>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e621590f0>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6216c9b0>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6216c9f0>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6215de30>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6215d7b0>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6216c7b0>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6216ca70>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6216c5f0>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6216c8b0>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6215d7b0>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6216ca30>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6216cbf0>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6216cab0>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6216cc30>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6215d7b0>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6216cd30>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6216cbb0>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6216cef0>,\n",
       " <pyrealsense2.pyrealsense2.pose_frame at 0x7f7e6216c970>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t265_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_diff_frames(frames):\n",
    "    prev_frame = None\n",
    "    for i, frame in enumerate(frames):\n",
    "        if prev_frame is not None:\n",
    "            print(\"Difference bw {0} and {1} frames is {2:.4f} ms\".format(i, i-1, frame.get_timestamp()-prev_frame.get_timestamp()))\n",
    "        prev_frame = frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_sensors(frames1, frames2):\n",
    "    if len(frames1) != len(frames2):\n",
    "        return\n",
    "    else:\n",
    "        for i in range(len(frames1)):\n",
    "            print(\"Difference bw frames1[{0}] and frames2[{0}] frames is {1:.4f} ms\".format(i, frames1[i].get_timestamp()-frames2[i].get_timestamp()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference bw 1 and 0 frames is 466.9939 ms\n",
      "Difference bw 2 and 1 frames is 466.9417 ms\n",
      "Difference bw 3 and 2 frames is 467.0337 ms\n",
      "Difference bw 4 and 3 frames is 466.8530 ms\n",
      "Difference bw 5 and 4 frames is 467.0156 ms\n",
      "Difference bw 6 and 5 frames is 466.9106 ms\n",
      "Difference bw 7 and 6 frames is 467.0164 ms\n",
      "Difference bw 8 and 7 frames is 466.8916 ms\n",
      "Difference bw 9 and 8 frames is 467.0095 ms\n",
      "Difference bw 10 and 9 frames is 466.9180 ms\n",
      "Difference bw 11 and 10 frames is 466.9651 ms\n",
      "Difference bw 12 and 11 frames is 467.0002 ms\n",
      "Difference bw 13 and 12 frames is 467.5154 ms\n",
      "Difference bw 14 and 13 frames is 466.3035 ms\n",
      "Difference bw 15 and 14 frames is 466.9458 ms\n",
      "Difference bw 16 and 15 frames is 466.9670 ms\n",
      "Difference bw 17 and 16 frames is 467.0144 ms\n",
      "Difference bw 18 and 17 frames is 467.0010 ms\n",
      "Difference bw 19 and 18 frames is 466.8860 ms\n",
      "Difference bw 20 and 19 frames is 466.8533 ms\n",
      "Difference bw 21 and 20 frames is 467.0469 ms\n",
      "Difference bw 22 and 21 frames is 466.9763 ms\n",
      "Difference bw 23 and 22 frames is 466.9116 ms\n",
      "Difference bw 24 and 23 frames is 466.9275 ms\n",
      "Difference bw 25 and 24 frames is 466.9702 ms\n",
      "Difference bw 1 and 0 frames is 464.9324 ms\n",
      "Difference bw 2 and 1 frames is 469.9175 ms\n",
      "Difference bw 3 and 2 frames is 464.9629 ms\n",
      "Difference bw 4 and 3 frames is -1399.8127 ms\n",
      "Difference bw 5 and 4 frames is 2334.8027 ms\n",
      "Difference bw 6 and 5 frames is 464.8042 ms\n",
      "Difference bw 7 and 6 frames is 469.8948 ms\n",
      "Difference bw 8 and 7 frames is 465.0676 ms\n",
      "Difference bw 9 and 8 frames is 469.7344 ms\n",
      "Difference bw 10 and 9 frames is 465.1367 ms\n",
      "Difference bw 11 and 10 frames is -4669.4404 ms\n",
      "Difference bw 12 and 11 frames is 5604.1555 ms\n",
      "Difference bw 13 and 12 frames is 464.8977 ms\n",
      "Difference bw 14 and 13 frames is 469.9607 ms\n",
      "Difference bw 15 and 14 frames is 464.9395 ms\n",
      "Difference bw 16 and 15 frames is -7003.9534 ms\n",
      "Difference bw 17 and 16 frames is 7938.8032 ms\n",
      "Difference bw 18 and 17 frames is 464.9795 ms\n",
      "Difference bw 19 and 18 frames is 469.8562 ms\n",
      "Difference bw 20 and 19 frames is 464.9270 ms\n",
      "Difference bw 21 and 20 frames is -9338.5659 ms\n",
      "Difference bw 22 and 21 frames is 10273.4175 ms\n",
      "Difference bw 23 and 22 frames is 464.9629 ms\n",
      "Difference bw 24 and 23 frames is 469.9753 ms\n",
      "Difference bw 25 and 24 frames is 464.9075 ms\n"
     ]
    }
   ],
   "source": [
    "count_diff_frames(d435_frames)\n",
    "count_diff_frames(t265_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference bw frames1[0] and frames2[0] frames is -4.2820 ms\n",
      "Difference bw frames1[1] and frames2[1] frames is -2.2205 ms\n",
      "Difference bw frames1[2] and frames2[2] frames is -5.1963 ms\n",
      "Difference bw frames1[3] and frames2[3] frames is -3.1255 ms\n",
      "Difference bw frames1[4] and frames2[4] frames is 1863.5403 ms\n",
      "Difference bw frames1[5] and frames2[5] frames is -4.2468 ms\n",
      "Difference bw frames1[6] and frames2[6] frames is -2.1404 ms\n",
      "Difference bw frames1[7] and frames2[7] frames is -5.0188 ms\n",
      "Difference bw frames1[8] and frames2[8] frames is -3.1948 ms\n",
      "Difference bw frames1[9] and frames2[9] frames is -5.9197 ms\n",
      "Difference bw frames1[10] and frames2[10] frames is -4.1384 ms\n",
      "Difference bw frames1[11] and frames2[11] frames is 5132.2671 ms\n",
      "Difference bw frames1[12] and frames2[12] frames is -4.8882 ms\n",
      "Difference bw frames1[13] and frames2[13] frames is -2.2705 ms\n",
      "Difference bw frames1[14] and frames2[14] frames is -5.9277 ms\n",
      "Difference bw frames1[15] and frames2[15] frames is -3.9214 ms\n",
      "Difference bw frames1[16] and frames2[16] frames is 7466.9990 ms\n",
      "Difference bw frames1[17] and frames2[17] frames is -4.7898 ms\n",
      "Difference bw frames1[18] and frames2[18] frames is -2.7683 ms\n",
      "Difference bw frames1[19] and frames2[19] frames is -5.7385 ms\n",
      "Difference bw frames1[20] and frames2[20] frames is -3.8123 ms\n",
      "Difference bw frames1[21] and frames2[21] frames is 9801.8005 ms\n",
      "Difference bw frames1[22] and frames2[22] frames is -4.6406 ms\n",
      "Difference bw frames1[23] and frames2[23] frames is -2.6919 ms\n",
      "Difference bw frames1[24] and frames2[24] frames is -5.7397 ms\n",
      "Difference bw frames1[25] and frames2[25] frames is -3.6770 ms\n"
     ]
    }
   ],
   "source": [
    "get_diff_sensors(d435_frames, t265_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "def timing(f):\n",
    "    @wraps(f)\n",
    "    def wrap(*args, **kw):\n",
    "        time_start = time.time()\n",
    "        result = f(*args, **kw)\n",
    "        time_end = time.time()\n",
    "        print('----------func:%r took: %2.4f sec' % (f.__name__, time_end-time_start))\n",
    "        return result\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_T265toD435 = np.array([[0.999968402, -0.006753626, -0.004188075, -0.015890727],\n",
    "                          [-0.006685408, -0.999848172, 0.016093893, 0.028273059],\n",
    "                          [-0.004296131, -0.016065384, -0.999861654, -0.009375589],\n",
    "                          [0, 0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph plot\n",
    "t265 = np.load('../logs/points_trajectory_T265.npy') #np array coords\n",
    "d435 = np.load('../logs/points_trajectory_D435.npy')/1 # np array coords\n",
    "# before = 10\n",
    "before = d435.shape[0]\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.plot(t265[:before, 0], t265[:before, 1], t265[:before, 2], label='t265')\n",
    "ax.plot(d435[:before, 0], d435[:before, 1], d435[:before, 2], label='d435')\n",
    "ax.view_init(elev=22, azim=80)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformation265(pose):\n",
    "    data = pose.get_pose_data()\n",
    "    data_rot = [float(i.strip('xyzw: ')) for i in str(data.rotation).split(', ')]\n",
    "    r = R.from_quat(data_rot)\n",
    "    rotation = np.array(r.as_dcm())\n",
    "    translation = np.array([float(i.strip('xyzw: ')) for i in str(data.translation).split(', ')])[np.newaxis].T\n",
    "    T = np.hstack((rotation, translation))\n",
    "    T = np.vstack((T, np.array([0, 0, 0, 1])))\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translation_pose(pose):\n",
    "    # https://github.com/IntelRealSense/librealsense/issues/5178\n",
    "    try:\n",
    "        data = pose.get_pose_data()\n",
    "        trans = data.translation\n",
    "        return np.array([trans.x, trans.y, trans.z]) # world(x,y,z) = real(-z,x,-y)\n",
    "#         return np.array([-trans.z, trans.x, -trans.y]) # world(x,y,z) = real(-z,x,-y)\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_translation_pose(t265_frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t265_translations = np.array([get_translation_pose(pose) for pose in t265_frames])\n",
    "t265_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_transformation265(t265_frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformation(transformation, points):\n",
    "    \"\"\"\n",
    "\n",
    "    :param transformation: 4x4 np.array\n",
    "    :param points: Nx3 np.array\n",
    "    :return: transformed Nx3 np.array\n",
    "    \"\"\"\n",
    "    if transformation is None or points is None:\n",
    "        return None\n",
    "    else:\n",
    "        coordinates = np.hstack((points, np.ones((points.shape[0], 1))))\n",
    "        return (transformation @ coordinates.T).T[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(depth_frame, make_sampling=True, koef = 2**2):\n",
    "    \"\"\"\n",
    "     TODO\n",
    "    :param make_sampling:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    pc = rs.pointcloud()\n",
    "    if make_sampling:\n",
    "        decimate = rs.decimation_filter()\n",
    "        decimate.set_option(rs.option.filter_magnitude, koef)\n",
    "        depth_frame = decimate.process(depth_frame)\n",
    "\n",
    "        points = pc.calculate(depth_frame).as_points()\n",
    "    else:\n",
    "        points = pc.calculate(depth_frame).as_points()\n",
    "\n",
    "    coordinates = np.ndarray(buffer=points.get_vertices(), dtype=np.float32, shape=(points.size(), 3))\n",
    "    coordinates = coordinates[coordinates[:, 2] != 0]\n",
    "\n",
    "    coordinates = apply_transformation(tm_T265toD435, coordinates)\n",
    "    return coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_coordinates(d435_frames[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_pcl(points):\n",
    "    \"\"\"\n",
    "        TODO\n",
    "    :param points: Nx3\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if points is None:\n",
    "        return None\n",
    "    else:\n",
    "        return o3d.geometry.PointCloud(o3d.utility.Vector3dVector(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_pcl(get_coordinates(d435_frames[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO this 100%\n",
    "\n",
    "def get_transformation435(self, max_point_pair_dist=0.2, init_guess=np.eye(4)):\n",
    "    old_point_cloud = self.apply_transformation(self.prev_tm, self.point_cloud)\n",
    "    old_pcl = self.convert_to_pcl(old_point_cloud) # n-1\n",
    "    self.point_cloud = self.apply_transformation(self.prev_tm, self.get_coordinates())\n",
    "    if old_pcl is None:\n",
    "        self.prev_tm = init_guess\n",
    "        print(\"\\n\\n\\n{}\\n\\n\\n\".format(init_guess))\n",
    "        return None\n",
    "\n",
    "    new_pcl = self.convert_to_pcl(self.point_cloud) # n\n",
    "\n",
    "    tr_mx = o3d.registration.registration_icp(old_pcl, new_pcl, max_point_pair_dist,\n",
    "                                              self.prev_tm, o3d.registration.TransformationEstimationPointToPoint())\\\n",
    "        .transformation\n",
    "    self.prev_tm = tr_mx\n",
    "    return tr_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PC(Y, TX, ax=None, plot_lines=True):\n",
    "    ax_is_None = False\n",
    "    if ax is None:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax_is_None = True\n",
    "    ax.plot(Y[:,0], Y[:,1], Y[:,2], 'o', label='source points')\n",
    "    ax.plot(TX[:,0], TX[:,1], TX[:,2], 'o', label='dest points')\n",
    "    if plot_lines:\n",
    "        for i in range(Y.shape[0]):\n",
    "            ax.plot([Y[i,0], TX[i,0]], [Y[i,1], TX[i,1]], [Y[i,2], TX[i,2]], \n",
    "                    'g--')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    ax.legend()\n",
    "    \n",
    "    if ax_is_None:\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d435_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t265_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "for i in range(len(d435_frames)):\n",
    "    clear_output(wait=True)\n",
    "    plt.imshow(d435_frames[i].get_data())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [get_coordinates(depth) for depth in d435_frames]\n",
    "pcl = [convert_to_pcl(point) for point in points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def registration_icp(prev_pc, new_pc, thresh):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    return o3d.registration.registration_icp(prev_pc, new_pc, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "regs = []\n",
    "tr_mxs = []\n",
    "\n",
    "for i in range(1, len(points)):\n",
    "    reg = registration_icp(pcl[i-1], pcl[i], 5)\n",
    "#     print(i, reg.fitness, reg.inlier_rmse)\n",
    "    tr_mx = reg.transformation\n",
    "    regs.append(reg)\n",
    "    tr_mxs.append(tr_mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_points = [reg.fitness for reg in regs]\n",
    "inlier_rmse_points = [reg.inlier_rmse for reg in regs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fitness_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(inlier_rmse_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_transf(points0, points1, reg, size=30):\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    cor = np.asarray(reg.correspondence_set)\n",
    "    set0 = points0[cor[:, 0]]\n",
    "    set1 = points1[cor[:, 1]]\n",
    "    inds = np.random.choice(len(cor), size=size, replace=False)\n",
    "    set0 = set0[inds]\n",
    "    set1 = set1[inds]\n",
    "    plot_PC(set0, set1, ax1)\n",
    "    Tset0 = (reg.transformation @ (np.vstack((set0.T, np.ones(set0.shape[0]))))).T\n",
    "    plot_PC(Tset0, set1, ax2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return set0, set1, Tset0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set0, set1, Tset0 = visualise_transf(points[0], points[1], regs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = [np.zeros(3)]\n",
    "R_ = np.eye(3)\n",
    "poses = [R_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tr_mxs)):\n",
    "    t_est = tr_mxs[0][:3, -1]\n",
    "    R_est = tr_mxs[0][:3, :3]\n",
    "\n",
    "    R_ = R_est @ R_\n",
    "    t = trajectory[-1] + (np.linalg.inv(R_) @ t_est).ravel()\n",
    "    \n",
    "    trajectory.append(t) #-t moves point cloud into (0,0) of the initial state \n",
    "    poses.append(R_) #R_^-1 translates point cloud into the state of initial frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = np.array(trajectory)\n",
    "plt.plot(trajectory[:, 1], trajectory[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pose(c, pose, ax):\n",
    "    for i, color in enumerate(['r', 'g', 'b']):\n",
    "        ax.plot([c[0], pose[0, i]+c[0]], \n",
    "                [c[1], pose[1, i]+c[1]],\n",
    "                [c[2], pose[2, i]+c[2]], color)\n",
    "    \n",
    "def plot_poses(trajectory, poses):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot(trajectory[:,0], trajectory[:, 1], trajectory[:,2], 'k')\n",
    "    for i, pose in enumerate(poses):\n",
    "        plot_pose(trajectory[i], pose, ax)\n",
    "#     ax.plot(points_trajectory_T265[:,0], points_trajectory_T265[:, 1], points_trajectory_T265[:, 2])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_poses(np.array(trajectory), np.array(poses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tr_mxs)):\n",
    "    _ = visualise_transf(points[i], points[i+1], regs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(points[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "tr = []\n",
    "for i in range(len(points)):\n",
    "#     ax.plot(points[i][:50,0], points[i][:50,1], points[i][:50,2], 'o', label=str(i))\n",
    "    tr.append(np.mean(points[i], axis=0))\n",
    "tr = np.array(tr)\n",
    "ax.plot(tr[:,0], tr[:, 1], tr[:, 2])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "# ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_trajectory_T265 = [[0, 0, 0]]\n",
    "for pose in t265_frames:\n",
    "    tr_mx = get_transformation265(pose)\n",
    "    points_trajectory_T265.append(tr_mx[:3, -1])\n",
    "points_trajectory_T265 = np.array(points_trajectory_T265)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(points_trajectory_T265[:, 1], points_trajectory_T265[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.plot(tr[:,0], tr[:, 1], tr[:, 2])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "# ax.legend()\n",
    "ax.plot(points_trajectory_T265[:,0], points_trajectory_T265[:, 1], points_trajectory_T265[:, 2])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation\n",
    "```\n",
    "pip install â€“upgrade pip\n",
    "pip install PyQT5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mxs_real = [tr_mxs[0]]\n",
    "for i in range(1, len(tr_mxs)):\n",
    "    tr_mxs_real.append(tr_mxs_real[-1] @ (tr_mxs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_points = [point[:3,-1] for point in tr_mxs_real]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_points = np.array(tr_points) * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_tr_e = [trajectory.tolist().index(i) for i in trajectory.tolist()]\n",
    "print(mark_tr_e)\n",
    "mark_tr = [tr_points.tolist().index(i) for i in tr_points.tolist()]\n",
    "print(mark_tr)\n",
    "\n",
    "mark_t265 = [t265_translations.tolist().index(i) for i in t265_translations.tolist()]\n",
    "print(mark_t265)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_t265_trajectory = np.array([get_translation_pose_from_data(pose) for pose in t265_frames_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig = plt.figure(figsize=(10,10), dpi=100)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.plot(tr[:,0], tr[:, 1], tr[:, 2])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "# ax.legend()\n",
    "# ax.plot(trajectory[:,0], trajectory[:, 1], trajectory[:, 2], label='d435_Elvira')\n",
    "# for i, txt in enumerate(mark_tr_e):\n",
    "#     ax.text(trajectory[i,0],trajectory[i,1],trajectory[i,2], txt)\n",
    "\n",
    "ax.plot(tr_points[:,0], tr_points[:, 1], tr_points[:, 2], label='d435_Elvira(post Valera)')\n",
    "for i, txt in enumerate(mark_tr):\n",
    "    ax.text(tr_points[i,0],tr_points[i,1],tr_points[i,2], txt)\n",
    "    \n",
    "ax.plot(t265_translations[:,0],t265_translations[:,1],t265_translations[:,2], label='t265')\n",
    "for i, txt in enumerate(mark_t265):\n",
    "    ax.text(t265_translations[i,0],t265_translations[i,1],t265_translations[i,2], txt)\n",
    "    \n",
    "# ax.plot(full_t265_trajectory[:,0],full_t265_trajectory[:,1],full_t265_trajectory[:,2], label='Full trajectory')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
